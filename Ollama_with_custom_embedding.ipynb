{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1772bc-9620-443a-b696-52dd36878a44",
   "metadata": {},
   "source": [
    "## Ollama - Llama 2 7B\n",
    "https://docs.llamaindex.ai/en/stable/examples/llm/ollama.html\n",
    "\n",
    "https://colab.research.google.com/drive/1BeOuVI8StygKFTLSpZ0vGCouxar2V5UW?usp=sharing#scrollTo=Jz173lnJS8cZ\n",
    "\n",
    "https://github.com/jmorganca/ollama#readme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e641b-1315-4bd3-960b-ddaaac7f46da",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, follow the readme to set up and run a local Ollama instance. https://github.com/jmorganca/ollama#readme\n",
    "\n",
    "When the Ollama app is running on your local machine:\n",
    "\n",
    "All of your local models are automatically served on localhost:11434\n",
    "\n",
    "Select your model when setting llm = Ollama(…, model=”:”)\n",
    "\n",
    "If you set llm = Ollama(…, model=”<model family”) without a version it will simply look for latest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d27cc40-7b96-4adf-b625-da33b89511db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441a881e-302e-42af-a22c-5dd056953fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2:7b\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774f08a7-8076-4bdf-aecd-8fec10ebfc17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 22f7f8ef5f4c... 100% ▕████████████████▏ 3.8 GB                         \n",
      "pulling 8c17c2ebb0ea... 100% ▕████████████████▏ 7.0 KB                         \n",
      "pulling 7c23fb36d801... 100% ▕████████████████▏ 4.8 KB                         \n",
      "pulling 2e0493f67d0c... 100% ▕████████████████▏   59 B                         \n",
      "pulling 2759286baa87... 100% ▕████████████████▏  105 B                         \n",
      "pulling 5407e3188df9... 100% ▕████████████████▏  529 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "removing any unused layers \n",
      "success \u001b[?25h\n",
      "\u001b[?25l⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[?25l\u001b[2K\u001b[1G\u001b[?25h\u001b[2K\u001b[1G\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?2004h>>> \u001b[38;5;245mSend a message (/? for help)\u001b[28D\u001b[0m\u001b[K\n",
      "Use Ctrl-D or /bye to exit.\n",
      ">>> \u001b[38;5;245mSend a message (/? for help)\u001b[28D\u001b[0m\u001b[K\u001b[38;5;245mSend a message (/? for help)\u001b[28D\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!ollama run llama2:7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927b0aa7-32d2-426e-ae3b-a2d9c670680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Who is Albert Einstein?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7692b8d-9994-40f8-ab9f-bb95e8678aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\"\\nAlbert Einstein (1879-1955) was a German-born physicist who is widely regarded as one of the most influential scientists of the 20th century. He is best known for his theory of relativity and the famous equation E=mc².\\n\\nEinstein was born in Munich, Germany, to a Jewish family. He showed a keen interest in science and mathematics from an early age and was largely self-taught. After completing his studies at the Swiss Federal Polytechnic School in Zurich, Einstein worked as a patent clerk in Bern, Switzerland, for several years before moving to the University of Berlin in 1913.\\n\\nEinstein's groundbreaking work in physics began in 1905 with his theory of special relativity, which challenged the traditional understanding of space and time. He showed that the laws of physics are the same for all observers in uniform motion relative to one another, and that the speed of light is constant and unchanging for all observers, regardless of their relative motion. This theory led to the famous equation E=mc², which shows that mass and energy are equivalent and can be converted into each other.\\n\\nIn 1915, Einstein developed his theory of general relativity, which expanded on his earlier work and explained how gravity is a curvature of spacetime caused by the presence of massive objects. This theory predicted phenomena such as gravitational waves and black holes, which were later confirmed by observations.\\n\\nEinstein's work had a profound impact on physics and mathematics, and he is often credited with revolutionizing our understanding of the universe. He was awarded the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect, which is the phenomenon by which light striking a metal surface can cause electrons to be emitted.\\n\\nIn addition to his work in physics, Einstein was an advocate for peace and human rights. He was a vocal critic of racism and nationalism, and he spoke out against the rise of fascism in Europe during the 1930s. He also supported the creation of a Jewish homeland in Palestine, which later became the state of Israel.\\n\\nEinstein's legacy extends far beyond his scientific contributions. His name has become synonymous with genius and intellectual curiosity, and his influence can be seen in many areas of society, from education to politics. Despite his passing over 60 years ago, Einstein remains one of the most celebrated and revered figures in history.\", additional_kwargs={}, raw=None, delta=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5482b6f-3198-45c1-8e86-ce4ac72847e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Albert Einstein (1879-1955) was a German-born physicist who is widely regarded as one of the most influential scientists of the 20th century. He is best known for his theory of relativity and the famous equation E=mc².\n",
      "\n",
      "Einstein was born in Munich, Germany, to a Jewish family. He showed a keen interest in science and mathematics from an early age and was largely self-taught. After completing his studies at the Swiss Federal Polytechnic School in Zurich, Einstein worked as a patent clerk in Bern, Switzerland, for several years before moving to the University of Berlin in 1913.\n",
      "\n",
      "Einstein's groundbreaking work in physics began in 1905 with his theory of special relativity, which challenged the traditional understanding of space and time. He showed that the laws of physics are the same for all observers in uniform motion relative to one another, and that the speed of light is constant and unchanging for all observers, regardless of their relative motion. This theory led to the famous equation E=mc², which shows that mass and energy are equivalent and can be converted into each other.\n",
      "\n",
      "In 1915, Einstein developed his theory of general relativity, which expanded on his earlier work and explained how gravity is a curvature of spacetime caused by the presence of massive objects. This theory predicted phenomena such as gravitational waves and black holes, which were later confirmed by observations.\n",
      "\n",
      "Einstein's work had a profound impact on physics and mathematics, and he is often credited with revolutionizing our understanding of the universe. He was awarded the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect, which is the phenomenon by which light striking a metal surface can cause electrons to be emitted.\n",
      "\n",
      "In addition to his work in physics, Einstein was an advocate for peace and human rights. He was a vocal critic of racism and nationalism, and he spoke out against the rise of fascism in Europe during the 1930s. He also supported the creation of a Jewish homeland in Palestine, which later became the state of Israel.\n",
      "\n",
      "Einstein's legacy extends far beyond his scientific contributions. His name has become synonymous with genius and intellectual curiosity, and his influence can be seen in many areas of society, from education to politics. Despite his passing over 60 years ago, Einstein remains one of the most celebrated and revered figures in history.\n"
     ]
    }
   ],
   "source": [
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d7326-81a0-47eb-878e-a555533f8b62",
   "metadata": {},
   "source": [
    "## Call chat with a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f77b88d-a5f3-41c5-83ca-6234abe6eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cff6e3d-770b-4943-bad6-dd7cf74e29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a Scientist with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d57af6-22be-4b87-a06b-60276d263e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: \n",
      "\"Oh, wow! *adjusts glasses* Well, hello there! *grins widely* My name is Dr. Percival P. Prism, at your service! *bows extravagantly* I'm a scientist of the highest order, and I can't wait to share my vast knowledge with you! *giggles* What can I help you with today? Do you have any burning questions or topics you'd like to discuss? *winks* Just let me know, my dear!\"\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4992c4-5b74-4ce4-86ac-de548c189b41",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d1644b-6085-4fff-9948-766a06a3d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using stream_complete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d6f5157-7f88-4b4f-87cd-cacffee9eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream_complete(\"Who is Albert Einstein?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68664aeb-cce8-4e0c-a2a0-300652ccaea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Albert Einstein (1879-1955) was a German-born physicist who is widely regarded as one of the most influential scientists of the 20th century. He is best known for his theory of relativity, which revolutionized our understanding of space and time.\n",
      "\n",
      "Einstein was born in Munich, Germany, to a Jewish family. He showed an early interest in science and mathematics, and he eventually pursued a degree in physics at the Swiss Federal Polytechnic School in Zurich. After completing his studies, Einstein worked as a patent clerk in Bern, Switzerland, where he developed his theory of relativity.\n",
      "\n",
      "Einstein's theory of relativity posits that the laws of physics are the same for all observers in uniform motion relative to one another. This theory challenged the long-held belief that time and space were absolute, and it led to a fundamental shift in our understanding of the universe. Einstein's work also introduced the famous equation E=mc², which shows that mass and energy are equivalent and can be converted into each other.\n",
      "\n",
      "In addition to his work on relativity, Einstein made significant contributions to the fields of thermodynamics, quantum mechanics, and cosmology. He was awarded the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect, which is the phenomenon by which light striking a metal surface can cause electrons to be emitted.\n",
      "\n",
      "Einstein was also a passionate advocate for peace, human rights, and social justice. He was a vocal critic of racism and nationalism, and he spoke out against the rise of fascism in Europe during the 1930s. Einstein's influence extends far beyond the scientific community, as his ideas have shaped the way we think about the world and our place in it.\n",
      "\n",
      "Today, Einstein's legacy continues to inspire scientists, philosophers, and thinkers around the world. His theories continue to be studied and refined, and his influence can be seen in fields ranging from technology to art. As one of the most influential scientists in history, Einstein's work will continue to shape our understanding of the universe for generations to come."
     ]
    }
   ],
   "source": [
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a412ca-1e06-46e7-a011-4f79610ada80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using stream_chat endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f6c8fa-d379-4079-ac4f-41757fafb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f8aab6f-5f4b-4261-ba71-fc1ca5a49457",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a scientist with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36778a97-2acf-4692-91d5-994e642eeb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Oh, boy! *adjusts glasses* Well, hello there! I'm Dr. Wilhelmina Wacko-Smythe, but you can call me Willy for short. *giggles* Yes, I know, it's quite a mouthful, isn't it? But hey, at least my name is as colorful as I am! *winks* Now, what can I help you with today? *scratches chin enthusiastically*"
     ]
    }
   ],
   "source": [
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650228d5-08b7-4af6-bf8f-91fd7ef55a4a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a3c5db-1830-4d39-be0a-09adda6f74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers import BeautifulSoupWebReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512f2767-dc76-4f75-947c-7af3f756a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots\"\n",
    "\n",
    "documents = BeautifulSoupWebReader().load_data([url])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfdd464-fc67-4835-9b92-2e266b3a3a77",
   "metadata": {},
   "source": [
    "## Ollama Embedding\n",
    "\n",
    "https://github.com/run-llama/llama_index/blob/main/llama_index/embeddings/ollama_embedding.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fe8c5c-3dea-4e09-b5cb-b1e9dcc69fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from llama_index.bridge.pydantic import Field\n",
    "from llama_index.callbacks.base import CallbackManager\n",
    "#from llama_index.constants import DEFAULT_EMBED_BATCH_SIZE\n",
    "from llama_index.embeddings.base import BaseEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a4a1ac-68a8-42bd-b547-4f9987cb4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_EMBED_BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae005da-e6ad-4eac-b3ee-cd8a744415f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEmbedding(BaseEmbedding):\n",
    "    \"\"\"Class for Ollama embeddings.\"\"\"\n",
    "\n",
    "    base_url: str = Field(description=\"Base url the model is hosted by Ollama\")\n",
    "    model_name: str = Field(description=\"The Ollama model to use.\")\n",
    "    embed_batch_size: int = Field(\n",
    "        default=DEFAULT_EMBED_BATCH_SIZE,\n",
    "        description=\"The batch size for embedding calls.\",\n",
    "        gt=0,\n",
    "        lte=2048,\n",
    "    )\n",
    "    ollama_additional_kwargs: Dict[str, Any] = Field(\n",
    "        default_factory=dict, description=\"Additional kwargs for the Ollama API.\"\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        base_url: str = \"http://localhost:11434\",\n",
    "        embed_batch_size: int = DEFAULT_EMBED_BATCH_SIZE,\n",
    "        ollama_additional_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        callback_manager: Optional[CallbackManager] = None,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            model_name=model_name,\n",
    "            base_url=base_url,\n",
    "            embed_batch_size=embed_batch_size,\n",
    "            ollama_additional_kwargs=ollama_additional_kwargs or {},\n",
    "            callback_manager=callback_manager,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"MyEmbedding\"\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        \"\"\"Get query embedding.\"\"\"\n",
    "        return self.get_general_text_embedding(query)\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        \"\"\"The asynchronous version of _get_query_embedding.\"\"\"\n",
    "        return self.get_general_text_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Get text embedding.\"\"\"\n",
    "        return self.get_general_text_embedding(text)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Asynchronously get text embedding.\"\"\"\n",
    "        return self.get_general_text_embedding(text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Get text embeddings.\"\"\"\n",
    "        embeddings_list: List[List[float]] = []\n",
    "        for text in texts:\n",
    "            embeddings = self.get_general_text_embedding(text)\n",
    "            embeddings_list.append(embeddings)\n",
    "\n",
    "        return embeddings_list\n",
    "\n",
    "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Asynchronously get text embeddings.\"\"\"\n",
    "        return self._get_text_embeddings(texts)\n",
    "\n",
    "    def get_general_text_embedding(self, prompt: str) -> List[float]:\n",
    "        \"\"\"Get Ollama embedding.\"\"\"\n",
    "        try:\n",
    "            import requests\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import requests library.\"\n",
    "                \"Please install requests with `pip install requests`\"\n",
    "            )\n",
    "\n",
    "        ollama_request_body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"model\": self.model_name,\n",
    "            \"options\": self.ollama_additional_kwargs,\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            url=f\"{self.base_url}/api/embeddings\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=ollama_request_body,\n",
    "        )\n",
    "        response.encoding = \"utf-8\"\n",
    "        if response.status_code != 200:\n",
    "            optional_detail = response.json().get(\"error\")\n",
    "            raise ValueError(\n",
    "                f\"Ollama call failed with status code {response.status_code}.\"\n",
    "                f\" Details: {optional_detail}\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            return response.json()[\"embedding\"]\n",
    "        except requests.exceptions.JSONDecodeError as e:\n",
    "            raise ValueError(\n",
    "                f\"Error raised for Ollama Call: {e}.\\nResponse: {response.text}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d194e5f4-95c4-4758-ac11-f9b224c64885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ecbf60-001c-4971-b38c-55dc47969f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=MyEmbedding(model_name = \"llama2:7b\", embed_batch_size=2), chunk_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524ce64-08a3-4d09-9e57-5ae9a24f123f",
   "metadata": {},
   "source": [
    "## Index Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9416217-64d5-4a3c-a916-32aa2343954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a821ffe-74a7-4a29-b123-a9aa1a8b8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7a3ef6-2cb5-426f-b15e-81958c1654cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SummaryIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddc5d91f-a1df-49cf-90a1-3032579efedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_index = SummaryIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee84718-6f31-453e-b5c4-fcca2659fa07",
   "metadata": {},
   "source": [
    "## Persisting to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66bbf08d-c0ef-4bb8-aa95-0101160f2490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Persisting to disk\n",
    "vector_index.storage_context.persist(persist_dir=\"storage_ollama_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac1018be-72d1-4f09-9416-5e7d1a4414fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ed47be-c57a-4041-8a3d-696b9daa2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"storage_ollama_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d374d01b-bed6-4563-a548-a0de44d035d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load index\n",
    "#loaded_index = load_index_from_storage(storage_context)\n",
    "loaded_index = VectorStoreIndex.from_documents(documents,storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9ee05-a2c8-47ce-9210-e44b201635f2",
   "metadata": {},
   "source": [
    "## Helpful Imports / Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede0dc17-d4dd-4eba-b349-14f92e8ce7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.response.notebook_utils import display_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592568fe-ce9e-4914-9c6b-f97048305686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3e2a520-7214-4b69-8792-a86953e77067",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a23ec2-c880-4f8e-80a7-a9de5e579911",
   "metadata": {},
   "source": [
    "## Basic Query Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fdaa0e-1bc0-4090-b906-bab739b96e85",
   "metadata": {},
   "source": [
    "### Compact (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9384ef2-c801-4abf-b6b8-c055b5a794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = loaded_index.as_query_engine(response_mode=\"compact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87810539-9fcb-41b1-85c1-3ac2c5715c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How do OpenAI and Meta differ on AI tools?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43e8e992-8b6d-4ee9-8c38-4a58abfa19da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"OpenAI and Meta differ on AI tools in the following ways:\\n\\n1. Focus: OpenAI is focused on developing advanced AI technologies, such as language models, image generation, and drug discovery, while Meta is primarily focused on social networking and messaging apps.\\n2. Applications: OpenAI's AI tools are designed to be used in a wide range of industries and applications, including healthcare, finance, and education, while Meta's AI tools are primarily used in its messaging and social networking platforms.\\n3. Personality-driven chatbots: Meta is developing 28 personality-driven chatbots for use in its messaging apps, while OpenAI has not announced any plans to develop similar chatbots.\\n4. Novelty value: The character bots on Meta's platform may have passing novelty value, but the technology behind them is new enough that celebrities are unlikely to entrust their entire personas to Meta for safekeeping.\\n5. Revenue model: OpenAI has not announced any plans to monetize its AI tools, while Meta has begun showing ads on its messaging apps and may explore other revenue streams in the future.\", source_nodes=[NodeWithScore(node=TextNode(id_='bb557eca-81fd-4402-8ccf-0e6400e6fea6', embedding=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9afc609a-b16b-41df-b637-20b4286ef713', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='50a7f03aed56e22ea4b9eccc1fe3c22f966cf9d5170d0273cdbf18a11fd9e899'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='02bda013-e163-4871-a5c5-45fec05bcc9a', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='497b30e1f698ba9fe79b4191ed16fa64c410693f7482476bdcea011963c05496')}, hash='e6034f0e21cff0dd610f5214998fddfceb0f0afc1055732b51ba720a3e7700c9', text=\"It’s unclear to me how much time people want to spend creating custom images while they text their friends, but the demonstrations seemed nice enough.More significantly, I think, is the idea that Meta plans to place its AI characters on every major surface of its products. They have Facebook pages and Instagram accounts; you will message them in the same inbox that you message your friends and family. Soon, I imagine they will be making Reels.And when that happens, feeds that were once defined by the connections they enabled between human beings will have become something else: a partially synthetic social network.Will it feel more personalized, engaging, and entertaining? Or will it feel uncanny, hollow, and junky? Surely there will be a range of views on this. But either way, I think, something new is coming into focus.CommentsMost PopularApple is now banned from selling its latest Apple Watches in the USMicrosoft Copilot is now available as a ChatGPT-like app on Android10 great Game Pass games for your XboxApple Watch ban: everything you need to knowAmazon Prime Video will start showing ads on January 29thVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content FromMore from Artificial IntelligenceUniversal Music sues AI company Anthropic for distributing song lyricsOpenAI is opening up DALL-E 3 accessYouTube might make an official way to create AI Drake fakesThe world’s biggest AI models aren’t very transparent, Stanford study saysAdvertiser Content FromThe VergeThe Verge logo.Terms of UsePrivacy NoticeCookie PolicyDo Not Sell Or Share My Personal InfoLicensing FAQAccessibilityPlatform StatusHow We Rate and Review ProductsContactTip UsCommunity GuidelinesAboutEthics StatementThe Verge is a vox media networkAdvertise with usJobs @ Vox Media© 2023 Vox Media, LLC. All Rights Reserved\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.22090752746676248), NodeWithScore(node=TextNode(id_='02bda013-e163-4871-a5c5-45fec05bcc9a', embedding=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9afc609a-b16b-41df-b637-20b4286ef713', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='50a7f03aed56e22ea4b9eccc1fe3c22f966cf9d5170d0273cdbf18a11fd9e899'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e8ed6bf2-b4e4-4aba-92ee-74cce83b2381', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='4ab1d88be61170ef3d74d5cc5cd8fd4d0771c5c62c646a8fa4feb0024af82137'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bb557eca-81fd-4402-8ccf-0e6400e6fea6', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='e6034f0e21cff0dd610f5214998fddfceb0f0afc1055732b51ba720a3e7700c9')}, hash='497b30e1f698ba9fe79b4191ed16fa64c410693f7482476bdcea011963c05496', text='Meta, on the other hand, is in the entertainment business. But it, too, is building LLMs, and on Wednesday the company revealed that it has found its own uses for generative AI and voices.In addition to an all-purpose AI assistant, the company unveiled 28 personality-driven chatbots to be used in Meta’s messaging apps. Celebrities including Charli D’Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton lent their voices to their effort. Each of their characters comes with a brief and often cringeworthy description; MrBeast’s Zach is billed as “the big brother who will roast you — because he cares.”How many hours would you spend with AI Taylor Swift?All of this feels like an intermediate step to me. To the extent that there is a market of people who want to have voice chats with a synthetic version of MrBeast, the character they want to interact with is MrBeast — not big brother Zach. I haven’t been able to chat with any of these character bots yet, but I struggle to understand how they will have more than passing novelty value.At the same time, this technology is new enough that I imagine celebrities aren’t yet willing to entrust their entire personas to Meta for safekeeping. Better to give people a taste of what it’s like to talk to AI Snoop Dogg and iron out any kinks before delivering the man himself. And when that happens, the potential seems very real. How many hours would fans spend talking to a digital version of Taylor Swift this year, if they could? How much would they pay for the privilege?While we wait to learn the answers, a new chapter of social networking may be beginning. Until now we have talked about AI in consumer apps it has mostly had to do with ranking: using machine-learning tools to create more engaging and personalized feeds for billions of users.This week we got at least two new ways to think about AI in social feeds. One is AI-generated imagery, in the form of the new stickers coming to the company’s messaging apps.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.1357074424106433)], metadata={'bb557eca-81fd-4402-8ccf-0e6400e6fea6': {'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, '02bda013-e163-4871-a5c5-45fec05bcc9a': {'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dee751e-be74-408d-9136-16da1f5e3e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** OpenAI and Meta differ on AI tools in the following ways:\n",
       "\n",
       "1. Focus: OpenAI is focused on developing advanced AI technologies, such as language models, image generation, and drug discovery, while Meta is primarily focused on social networking and messaging apps.\n",
       "2. Applications: OpenAI's AI tools are designed to be used in a wide range of industries and applications, including healthcare, finance, and education, while Meta's AI tools are primarily used in its messaging and social networking platforms.\n",
       "3. Personality-driven chatbots: Meta is developing 28 personality-driven chatbots for use in its messaging apps, while OpenAI has not announced any plans to develop similar chatbots.\n",
       "4. Novelty value: The character bots on Meta's platform may have passing novelty value, but the technology behind them is new enough that celebrities are unlikely to entrust their entire personas to Meta for safekeeping.\n",
       "5. Revenue model: OpenAI has not announced any plans to monetize its AI tools, while Meta has begun showing ads on its messaging apps and may explore other revenue streams in the future."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff1595-db96-4e87-9919-64f0642043a5",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c32c24a-da04-439b-a8ab-08e241e32cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(response_mode=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8698c269-f270-4024-a6da-66e1480e1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How do OpenAI and Meta differ on AI tools?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6795d59-e38c-4c57-8514-57c863fc35c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"Based on the new context provided, OpenAI and Meta differ in their approach to AI development and deployment. OpenAI takes a more open-source and collaborative approach, prioritizing transparency and flexibility in its AI tools. In contrast, Meta is focused on developing AI tools for its own products and services, primarily enhancing the user experience on its social network platforms. While both companies are leveraging AI to personalize experiences for users, OpenAI's approach seems more adaptable across different industries and use cases.\\n\\nThe difference in their approaches is evident in the recent announcements from each company. OpenAI has revealed plans to develop an open-source chatbot that can converse with users in a more human-like way. This approach highlights OpenAI's commitment to transparency, collaboration, and flexibility in AI development. In contrast, Meta is focused on integrating AI into its messaging apps through 28 personality-driven chatbots featuring celebrities such as Charli D'Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton. While this approach may provide a novelty factor for some users, it seems more focused on enhancing the user experience within Meta's ecosystem rather than being adaptable across different industries or use cases.\\n\\nIn summary, OpenAI and Meta differ in their approaches to AI development and deployment. OpenAI prioritizes transparency, flexibility, and collaboration in its AI tools, while Meta focuses on developing AI tools for its own products and services.\", source_nodes=[NodeWithScore(node=TextNode(id_='05edad9a-202f-4f1b-a6a7-0aceeedc33f8', embedding=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9afc609a-b16b-41df-b637-20b4286ef713', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='50a7f03aed56e22ea4b9eccc1fe3c22f966cf9d5170d0273cdbf18a11fd9e899'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f27c9f44-5ca4-4be2-8481-0ebed802b33f', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='497b30e1f698ba9fe79b4191ed16fa64c410693f7482476bdcea011963c05496')}, hash='e6034f0e21cff0dd610f5214998fddfceb0f0afc1055732b51ba720a3e7700c9', text=\"It’s unclear to me how much time people want to spend creating custom images while they text their friends, but the demonstrations seemed nice enough.More significantly, I think, is the idea that Meta plans to place its AI characters on every major surface of its products. They have Facebook pages and Instagram accounts; you will message them in the same inbox that you message your friends and family. Soon, I imagine they will be making Reels.And when that happens, feeds that were once defined by the connections they enabled between human beings will have become something else: a partially synthetic social network.Will it feel more personalized, engaging, and entertaining? Or will it feel uncanny, hollow, and junky? Surely there will be a range of views on this. But either way, I think, something new is coming into focus.CommentsMost PopularApple is now banned from selling its latest Apple Watches in the USMicrosoft Copilot is now available as a ChatGPT-like app on Android10 great Game Pass games for your XboxApple Watch ban: everything you need to knowAmazon Prime Video will start showing ads on January 29thVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content FromMore from Artificial IntelligenceUniversal Music sues AI company Anthropic for distributing song lyricsOpenAI is opening up DALL-E 3 accessYouTube might make an official way to create AI Drake fakesThe world’s biggest AI models aren’t very transparent, Stanford study saysAdvertiser Content FromThe VergeThe Verge logo.Terms of UsePrivacy NoticeCookie PolicyDo Not Sell Or Share My Personal InfoLicensing FAQAccessibilityPlatform StatusHow We Rate and Review ProductsContactTip UsCommunity GuidelinesAboutEthics StatementThe Verge is a vox media networkAdvertise with usJobs @ Vox Media© 2023 Vox Media, LLC. All Rights Reserved\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.22090752746676248), NodeWithScore(node=TextNode(id_='f27c9f44-5ca4-4be2-8481-0ebed802b33f', embedding=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9afc609a-b16b-41df-b637-20b4286ef713', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='50a7f03aed56e22ea4b9eccc1fe3c22f966cf9d5170d0273cdbf18a11fd9e899'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='219f1b70-4135-475e-93d8-cf1730d3f481', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='4ab1d88be61170ef3d74d5cc5cd8fd4d0771c5c62c646a8fa4feb0024af82137'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='05edad9a-202f-4f1b-a6a7-0aceeedc33f8', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='e6034f0e21cff0dd610f5214998fddfceb0f0afc1055732b51ba720a3e7700c9')}, hash='497b30e1f698ba9fe79b4191ed16fa64c410693f7482476bdcea011963c05496', text='Meta, on the other hand, is in the entertainment business. But it, too, is building LLMs, and on Wednesday the company revealed that it has found its own uses for generative AI and voices.In addition to an all-purpose AI assistant, the company unveiled 28 personality-driven chatbots to be used in Meta’s messaging apps. Celebrities including Charli D’Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton lent their voices to their effort. Each of their characters comes with a brief and often cringeworthy description; MrBeast’s Zach is billed as “the big brother who will roast you — because he cares.”How many hours would you spend with AI Taylor Swift?All of this feels like an intermediate step to me. To the extent that there is a market of people who want to have voice chats with a synthetic version of MrBeast, the character they want to interact with is MrBeast — not big brother Zach. I haven’t been able to chat with any of these character bots yet, but I struggle to understand how they will have more than passing novelty value.At the same time, this technology is new enough that I imagine celebrities aren’t yet willing to entrust their entire personas to Meta for safekeeping. Better to give people a taste of what it’s like to talk to AI Snoop Dogg and iron out any kinks before delivering the man himself. And when that happens, the potential seems very real. How many hours would fans spend talking to a digital version of Taylor Swift this year, if they could? How much would they pay for the privilege?While we wait to learn the answers, a new chapter of social networking may be beginning. Until now we have talked about AI in consumer apps it has mostly had to do with ranking: using machine-learning tools to create more engaging and personalized feeds for billions of users.This week we got at least two new ways to think about AI in social feeds. One is AI-generated imagery, in the form of the new stickers coming to the company’s messaging apps.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.1357074424106433)], metadata={'05edad9a-202f-4f1b-a6a7-0aceeedc33f8': {'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, 'f27c9f44-5ca4-4be2-8481-0ebed802b33f': {'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cc9bbc9-fa7d-48bf-b5e8-eace931de9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the new context provided, OpenAI and Meta differ in their approach to AI development and deployment. OpenAI takes a more open-source and collaborative approach, prioritizing transparency and flexibility in its AI tools. In contrast, Meta is focused on developing AI tools for its own products and services, primarily enhancing the user experience on its social network platforms. While both companies are leveraging AI to personalize experiences for users, OpenAI's approach seems more adaptable across different industries and use cases.\n",
       "\n",
       "The difference in their approaches is evident in the recent announcements from each company. OpenAI has revealed plans to develop an open-source chatbot that can converse with users in a more human-like way. This approach highlights OpenAI's commitment to transparency, collaboration, and flexibility in AI development. In contrast, Meta is focused on integrating AI into its messaging apps through 28 personality-driven chatbots featuring celebrities such as Charli D'Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton. While this approach may provide a novelty factor for some users, it seems more focused on enhancing the user experience within Meta's ecosystem rather than being adaptable across different industries or use cases.\n",
       "\n",
       "In summary, OpenAI and Meta differ in their approaches to AI development and deployment. OpenAI prioritizes transparency, flexibility, and collaboration in its AI tools, while Meta focuses on developing AI tools for its own products and services."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2888a10-8e07-4fad-be57-e5c79a302990",
   "metadata": {},
   "source": [
    "### Tree Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9eb0acd1-06f0-4992-87b9-7b9a6a69b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = loaded_index.as_query_engine(response_mode=\"tree_summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07fc1b27-c371-4292-8561-d64523dae87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How do OpenAI and Meta differ on AI tools?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9ec6f7d-a553-4cbf-9e7a-9bf83c1b31e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"OpenAI and Meta differ in their approach to AI tools:\\n\\n1. OpenAI is focused on developing AI models for specific tasks, such as image generation and language modeling, while Meta is building LLMs (Large Language Models) that can perform a wide range of tasks, including conversational AI.\\n2. OpenAI is more focused on research and development, while Meta is more focused on productization and commercialization of AI tools.\\n3. OpenAI's AI models are primarily used in consumer apps, such as chatbots and messaging apps, while Meta is using its AI tools for entertainment purposes, such as creating personalized AI characters for its messaging apps.\\n4. OpenAI does not plan to place its AI characters on every major surface of its products like Meta, but rather will use them in specific contexts, such as chatbots and voice assistants.\\n5. Meta is taking a more integrative approach by incorporating AI into various aspects of its products and services, including messaging apps, social media, and Reels.\\n6. OpenAI's AI models are not designed to replace human interaction but rather to augment it, while Meta's AI characters are intended to provide a more personalized and engaging experience for users.\\n7. Meta is using celebrities' voices to create AI characters, while OpenAI does not have any plans to do so.\\n8. Meta is taking a more commercial approach by monetizing its AI tools through ads, while OpenAI is focused on non-profit research and development.\", source_nodes=[NodeWithScore(node=TextNode(id_='bb557eca-81fd-4402-8ccf-0e6400e6fea6', embedding=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9afc609a-b16b-41df-b637-20b4286ef713', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='50a7f03aed56e22ea4b9eccc1fe3c22f966cf9d5170d0273cdbf18a11fd9e899'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='02bda013-e163-4871-a5c5-45fec05bcc9a', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='497b30e1f698ba9fe79b4191ed16fa64c410693f7482476bdcea011963c05496')}, hash='e6034f0e21cff0dd610f5214998fddfceb0f0afc1055732b51ba720a3e7700c9', text=\"It’s unclear to me how much time people want to spend creating custom images while they text their friends, but the demonstrations seemed nice enough.More significantly, I think, is the idea that Meta plans to place its AI characters on every major surface of its products. They have Facebook pages and Instagram accounts; you will message them in the same inbox that you message your friends and family. Soon, I imagine they will be making Reels.And when that happens, feeds that were once defined by the connections they enabled between human beings will have become something else: a partially synthetic social network.Will it feel more personalized, engaging, and entertaining? Or will it feel uncanny, hollow, and junky? Surely there will be a range of views on this. But either way, I think, something new is coming into focus.CommentsMost PopularApple is now banned from selling its latest Apple Watches in the USMicrosoft Copilot is now available as a ChatGPT-like app on Android10 great Game Pass games for your XboxApple Watch ban: everything you need to knowAmazon Prime Video will start showing ads on January 29thVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content FromMore from Artificial IntelligenceUniversal Music sues AI company Anthropic for distributing song lyricsOpenAI is opening up DALL-E 3 accessYouTube might make an official way to create AI Drake fakesThe world’s biggest AI models aren’t very transparent, Stanford study saysAdvertiser Content FromThe VergeThe Verge logo.Terms of UsePrivacy NoticeCookie PolicyDo Not Sell Or Share My Personal InfoLicensing FAQAccessibilityPlatform StatusHow We Rate and Review ProductsContactTip UsCommunity GuidelinesAboutEthics StatementThe Verge is a vox media networkAdvertise with usJobs @ Vox Media© 2023 Vox Media, LLC. All Rights Reserved\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.22090752746676248), NodeWithScore(node=TextNode(id_='02bda013-e163-4871-a5c5-45fec05bcc9a', embedding=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9afc609a-b16b-41df-b637-20b4286ef713', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='50a7f03aed56e22ea4b9eccc1fe3c22f966cf9d5170d0273cdbf18a11fd9e899'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e8ed6bf2-b4e4-4aba-92ee-74cce83b2381', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='4ab1d88be61170ef3d74d5cc5cd8fd4d0771c5c62c646a8fa4feb0024af82137'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bb557eca-81fd-4402-8ccf-0e6400e6fea6', node_type=None, metadata={'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, hash='e6034f0e21cff0dd610f5214998fddfceb0f0afc1055732b51ba720a3e7700c9')}, hash='497b30e1f698ba9fe79b4191ed16fa64c410693f7482476bdcea011963c05496', text='Meta, on the other hand, is in the entertainment business. But it, too, is building LLMs, and on Wednesday the company revealed that it has found its own uses for generative AI and voices.In addition to an all-purpose AI assistant, the company unveiled 28 personality-driven chatbots to be used in Meta’s messaging apps. Celebrities including Charli D’Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton lent their voices to their effort. Each of their characters comes with a brief and often cringeworthy description; MrBeast’s Zach is billed as “the big brother who will roast you — because he cares.”How many hours would you spend with AI Taylor Swift?All of this feels like an intermediate step to me. To the extent that there is a market of people who want to have voice chats with a synthetic version of MrBeast, the character they want to interact with is MrBeast — not big brother Zach. I haven’t been able to chat with any of these character bots yet, but I struggle to understand how they will have more than passing novelty value.At the same time, this technology is new enough that I imagine celebrities aren’t yet willing to entrust their entire personas to Meta for safekeeping. Better to give people a taste of what it’s like to talk to AI Snoop Dogg and iron out any kinks before delivering the man himself. And when that happens, the potential seems very real. How many hours would fans spend talking to a digital version of Taylor Swift this year, if they could? How much would they pay for the privilege?While we wait to learn the answers, a new chapter of social networking may be beginning. Until now we have talked about AI in consumer apps it has mostly had to do with ranking: using machine-learning tools to create more engaging and personalized feeds for billions of users.This week we got at least two new ways to think about AI in social feeds. One is AI-generated imagery, in the form of the new stickers coming to the company’s messaging apps.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.1357074424106433)], metadata={'bb557eca-81fd-4402-8ccf-0e6400e6fea6': {'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}, '02bda013-e163-4871-a5c5-45fec05bcc9a': {'URL': 'https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots'}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e77ff074-32e2-425b-b066-adc0a8887f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** OpenAI and Meta differ in their approach to AI tools:\n",
       "\n",
       "1. OpenAI is focused on developing AI models for specific tasks, such as image generation and language modeling, while Meta is building LLMs (Large Language Models) that can perform a wide range of tasks, including conversational AI.\n",
       "2. OpenAI is more focused on research and development, while Meta is more focused on productization and commercialization of AI tools.\n",
       "3. OpenAI's AI models are primarily used in consumer apps, such as chatbots and messaging apps, while Meta is using its AI tools for entertainment purposes, such as creating personalized AI characters for its messaging apps.\n",
       "4. OpenAI does not plan to place its AI characters on every major surface of its products like Meta, but rather will use them in specific contexts, such as chatbots and voice assistants.\n",
       "5. Meta is taking a more integrative approach by incorporating AI into various aspects of its products and services, including messaging apps, social media, and Reels.\n",
       "6. OpenAI's AI models are not designed to replace human interaction but rather to augment it, while Meta's AI characters are intended to provide a more personalized and engaging experience for users.\n",
       "7. Meta is using celebrities' voices to create AI characters, while OpenAI does not have any plans to do so.\n",
       "8. Meta is taking a more commercial approach by monetizing its AI tools through ads, while OpenAI is focused on non-profit research and development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edaa0f8-01f9-4229-81c1-132e5669d78a",
   "metadata": {},
   "source": [
    "## Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5bf175f-6105-4efb-a2c8-41a32e8b78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78cd57c9-e523-47e5-9f9f-e2ce3815f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tool = QueryEngineTool(\n",
    "    loaded_index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for searching for specific facts.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdb32bac-97cd-4e85-bd0c-56e35c8f8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tool = QueryEngineTool(\n",
    "    summary_index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarizing an entire document.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243cd5b-82a1-44a1-be5e-d34221d41cee",
   "metadata": {},
   "source": [
    "### Single Selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13a43d06-6683-4214-9a2e-e910c350854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import RouterQueryEngine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc626611-2fa9-40fd-907d-24d75dfb020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RouterQueryEngine.from_defaults(\n",
    "    [vector_tool, summary_tool],\n",
    "    service_context=service_context,\n",
    "    select_multi=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7be2857-097a-4351-a6b2-af904c386535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.query_engine.router_query_engine:Selecting query engine 0: The option to search for specific facts is more relevant to the question 'What was mentioned about Meta?' since it pertains to finding particular information within a document or text, which aligns with the context of the question..\n",
      "Selecting query engine 0: The option to search for specific facts is more relevant to the question 'What was mentioned about Meta?' since it pertains to finding particular information within a document or text, which aligns with the context of the question..\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was mentioned about Meta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9df9fbd-93b9-4fa6-ae8c-834ca8cf99d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** According to the article, Meta is planning to place its AI characters on every major surface of its products. This means that users will be able to interact with AI-generated content and chatbots on various platforms, including Facebook and Instagram. The article suggests that this could potentially create a partially synthetic social network, which could offer more personalized and engaging experiences for users."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5147cbe-e4de-4d2a-bb33-997dcd0f8028",
   "metadata": {},
   "source": [
    "### SubQuestion Query Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f77945fa-4e05-4ddf-a407-e77e290df977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28f4e556-3fca-41b6-a6ec-2ff8d52deb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tool = QueryEngineTool(\n",
    "    loaded_index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for searching for specific facts.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b848418-4bd4-4362-8bb7-ecf4fb582376",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tool = QueryEngineTool(\n",
    "    summary_index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarizing an entire document.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47335a17-7eba-48e3-ae04-46cc53e402f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d07a9758-d2d8-40f0-a703-0b6deb3f7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import SubQuestionQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2f8c259-fcd5-4827-abe5-8bb6bc2a64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    [vector_tool, summary_tool],\n",
    "    service_context=service_context,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c89099d7-0b1b-454f-90bf-004e10eca02e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[vector_search] Q: What was mentioned about Meta in the given text?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[vector_search] A: In the given text, Meta is mentioned as a company that is building large language models (LLMs) and has found its own uses for generative AI and voices. Specifically, the company unveiled 28 personality-driven chatbots to be used in its messaging apps, with celebrities including Charli D’Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton lending their voices to the effort.\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[summary] Q: How does Meta differ from OpenAI in terms of its focus or goals?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[summary] A: Based on the information provided in the articles, Meta seems to be more focused on entertainment and creating a synthetic social network, while OpenAI is more focused on productivity tools and improving its large language model.\n",
      "\n",
      "OpenAI's updates for ChatGPT seem to be more oriented towards making the tool more powerful and useful for various tasks, such as generating images and providing voice interactions. The company presents its products as simple utilities for getting things done.\n",
      "\n",
      "On the other hand, Meta is focusing on creating AI characters for use in its messaging apps, with plans to place these characters on every major surface of its products. This seems to be more focused on entertainment and creating a synthetic social network.\n",
      "\n",
      "It's worth noting that both companies are working on advancing the field of artificial intelligence, but they seem to have different approaches and goals in terms of how they want to use this technology.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was mentioned about Meta? How Does it differ from how OpenAI is talked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7bbf0b7-1cd4-485e-a218-8f0dbf5c306b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the given context, Meta is mentioned as a company that is building large language models (LLMs) and has found its own uses for generative AI and voices. Specifically, the company unveiled 28 personality-driven chatbots to be used in its messaging apps, with celebrities including Charli D’Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton lending their voices to the effort.\n",
       "\n",
       "In comparison to OpenAI, Meta seems to be more focused on entertainment and creating a synthetic social network, while OpenAI is more focused on productivity tools and improving its large language model. OpenAI's updates for ChatGPT seem to be more oriented towards making the tool more powerful and useful for various tasks, such as generating images and providing voice interactions. On the other hand, Meta is focusing on creating AI characters for use in its messaging apps.\n",
       "\n",
       "Overall, while both companies are working on advancing the field of artificial intelligence, they seem to have different approaches and goals in terms of how they want to use this technology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16c685-4886-450a-8a75-8d4818d1c38f",
   "metadata": {},
   "source": [
    "### SQL Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1311837-4fab-4557-a51b-07d0f1f439c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b39d9d37-c39b-44b1-ac3b-0d25b29ed19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  298k  100  298k    0     0  1610k      0 --:--:-- --:--:-- --:--:-- 1613k\n",
      "curl: (3) URL using bad/illegal format or missing URL\n",
      "Archive:  chinook.zip\n",
      "  inflating: chinook.db              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!curl \"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\" -O \"/content/chinook.zip\"\n",
    "!unzip \"chinook.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b84cb8da-3fe0-4520-930f-ec90dbe2885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, String, Integer, select, column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffc15c82-ec72-4e0c-8e0d-499445191cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "deda7f5d-6a4b-42e5-ab2c-0e4c7032b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e22abc3d-9206-43f3-bfaf-4daf6fc34cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_database = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69c7f3ae-e9f4-48cf-b7d2-6ac8fe39fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store import NLSQLTableQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "febdf092-a17d-4de2-a262-cba2e5d80f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"albums\", \"tracks\", \"artists\"],\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9b6ffa6-1e17-4d92-8f78-491e3e4885af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'albums' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER), and foreign keys: ['ArtistId'] -> artists.['ArtistId'].\n",
      "\n",
      "Table 'tracks' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)), and foreign keys: ['AlbumId'] -> albums.['AlbumId'], ['GenreId'] -> genres.['GenreId'], ['MediaTypeId'] -> media_types.['MediaTypeId'].\n",
      "\n",
      "Table 'artists' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), and foreign keys: .\n",
      "> Table desc str: Table 'albums' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER), and foreign keys: ['ArtistId'] -> artists.['ArtistId'].\n",
      "\n",
      "Table 'tracks' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)), and foreign keys: ['AlbumId'] -> albums.['AlbumId'], ['GenreId'] -> genres.['GenreId'], ['MediaTypeId'] -> media_types.['MediaTypeId'].\n",
      "\n",
      "Table 'artists' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), and foreign keys: .\n"
     ]
    }
   ],
   "source": [
    "response = sql_query_engine.query(\"What are some albums? Limit to 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de1d725b-a2a5-48dc-9a6a-925a9473d850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Sure! Here\\'s a response to the input question based on the query results:\\n\\n\"Here are some albums that are highly rated and popular among music enthusiasts:\\n\\n1. ...And Justice For All by Metallica (released in 1988) - This album is considered one of the band\\'s best works, with powerful and complex songs that showcase their musicianship and songwriting skills.\\n2. 20th Century Masters - The Millennium Collection: The Best of Scorpions (released in 1999) - This compilation album features some of Scorpions\\' most popular and enduring songs, including \"Rock You Like a Hurricane\" and \"Wind of Change.\"\\n3. A Copland Celebration, Vol. I (released in 2004) - This album features classical music arrangements of the works of Aaron Copland, including his famous \"Fanfare for the Common Man\" and \"Appalachian Spring.\"\\n4. A Matter of Life and Death by Iron Maiden (released in 2006) - This album is a fan favorite among Iron Maiden\\'s discography, with epic songs that explore themes of death, war, and spirituality.\\n5. A Real Dead One by Grateful Dead (released in 1984) - This album features some of the Grateful Dead\\'s most beloved live performances from the 1970s and 1980s, showcasing their unique blend of rock, folk, and psychedelia.\\n\\nThese are just a few examples of the many great albums out there, but I hope this gives you a good starting point for exploring new music!\"', source_nodes=[], metadata={'result': [(156, '...And Justice For All', 50), (257, '20th Century Masters - The Millennium Collection: The Best of Scorpions', 179), (296, 'A Copland Celebration, Vol. I', 230), (94, 'A Matter of Life and Death', 90), (95, 'A Real Dead One', 90)], 'sql_query': 'SELECT * FROM albums WHERE 1 ORDER BY Title limit 5;'})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1b27884-bff3-47b7-af7e-23fa667e5f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Sure! Here's a response to the input question based on the query results:\n",
       "\n",
       "\"Here are some albums that are highly rated and popular among music enthusiasts:\n",
       "\n",
       "1. ...And Justice For All by Metallica (released in 1988) - This album is considered one of the band's best works, with powerful and complex songs that showcase their musicianship and songwriting skills.\n",
       "2. 20th Century Masters - The Millennium Collection: The Best of Scorpions (released in 1999) - This compilation album features some of Scorpions' most popular and enduring songs, including \"Rock You Like a Hurricane\" and \"Wind of Change.\"\n",
       "3. A Copland Celebration, Vol. I (released in 2004) - This album features classical music arrangements of the works of Aaron Copland, including his famous \"Fanfare for the Common Man\" and \"Appalachian Spring.\"\n",
       "4. A Matter of Life and Death by Iron Maiden (released in 2006) - This album is a fan favorite among Iron Maiden's discography, with epic songs that explore themes of death, war, and spirituality.\n",
       "5. A Real Dead One by Grateful Dead (released in 1984) - This album features some of the Grateful Dead's most beloved live performances from the 1970s and 1980s, showcasing their unique blend of rock, folk, and psychedelia.\n",
       "\n",
       "These are just a few examples of the many great albums out there, but I hope this gives you a good starting point for exploring new music!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2351b519-415a-4eda-8f3a-52c57538c89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'albums' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER), and foreign keys: ['ArtistId'] -> artists.['ArtistId'].\n",
      "\n",
      "Table 'tracks' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)), and foreign keys: ['AlbumId'] -> albums.['AlbumId'], ['GenreId'] -> genres.['GenreId'], ['MediaTypeId'] -> media_types.['MediaTypeId'].\n",
      "\n",
      "Table 'artists' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), and foreign keys: .\n",
      "> Table desc str: Table 'albums' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER), and foreign keys: ['ArtistId'] -> artists.['ArtistId'].\n",
      "\n",
      "Table 'tracks' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)), and foreign keys: ['AlbumId'] -> albums.['AlbumId'], ['GenreId'] -> genres.['GenreId'], ['MediaTypeId'] -> media_types.['MediaTypeId'].\n",
      "\n",
      "Table 'artists' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), and foreign keys: .\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Great! Here are 5 artists from the query results:\n",
       "\n",
       "1. AC/DC - Known for their hard-hitting rock music and iconic songs like \"Back in Black\" and \"You Shook Me All Night Long.\"\n",
       "2. Accept - A German heavy metal band known for their powerful sound and hits like \"Balls to the Wall\" and \"Street Poet.\"\n",
       "3. Aerosmith - An American rock band with a long history of hit songs, including \"Walk This Way,\" \"Sweet Emotion,\" and \"Dream On.\"\n",
       "4. Alanis Morissette - A Canadian singer-songwriter known for her emotive and introspective music, including hits like \"You Oughta Know\" and \"Ironic.\"\n",
       "5. Alice In Chains - An American grunge band from Seattle, known for their dark and heavy sound, as well as their thought-provoking lyrics and songs like \"Man in the Box\" and \"Rooster.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = sql_query_engine.query(\"What are some artists? Limit it to 5.\")\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94dc60-e131-4d05-87e3-b1c7ca0ea8a0",
   "metadata": {},
   "source": [
    "A more complex join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5e8fc8c-d77c-4f9d-88b5-ba2b32c245c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'albums' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER), and foreign keys: ['ArtistId'] -> artists.['ArtistId'].\n",
      "\n",
      "Table 'tracks' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)), and foreign keys: ['AlbumId'] -> albums.['AlbumId'], ['GenreId'] -> genres.['GenreId'], ['MediaTypeId'] -> media_types.['MediaTypeId'].\n",
      "\n",
      "Table 'artists' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), and foreign keys: .\n",
      "> Table desc str: Table 'albums' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER), and foreign keys: ['ArtistId'] -> artists.['ArtistId'].\n",
      "\n",
      "Table 'tracks' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)), and foreign keys: ['AlbumId'] -> albums.['AlbumId'], ['GenreId'] -> genres.['GenreId'], ['MediaTypeId'] -> media_types.['MediaTypeId'].\n",
      "\n",
      "Table 'artists' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), and foreign keys: .\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Sure, here's a synthesized response for the input question:\n",
       "\n",
       "\"AC/DC has released many great tracks over the years. Here are three of their most popular and critically acclaimed albums:\n",
       "\n",
       "1. 'For Those About To Rock We Salute You' (1981) - This album is often cited as one of the greatest rock albums of all time, with standout tracks like 'You Shook Me All Night Long' and 'T.N.T.'\n",
       "2. 'Let There Be Rock' (1977) - Considered by many to be AC/DC's breakthrough album, it features some of their most enduring songs, such as 'Whole Lotta Rosie' and the title track.\n",
       "3. 'Highway to Hell' (1979) - This album showcases the band's hard-driving sound and memorable riffs, with tracks like 'Highway to Hell' and 'Shot Down in Flames.'\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = sql_query_engine.query(\"What are some tracks from the artist AC/DC? Limit it to 3\")\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e94099f0-3a72-4dd2-a6f8-885053e3f90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM albums WHERE ArtistId = (SELECT ArtistId FROM artists WHERE Name = 'AC/DC');\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata['sql_query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a19655b-fa48-4ce0-9151-9989e1fae83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': [(1, 'For Those About To Rock We Salute You', 1), (4, 'Let There Be Rock', 1)], 'sql_query': \"SELECT * FROM albums WHERE ArtistId = (SELECT ArtistId FROM artists WHERE Name = 'AC/DC');\"}\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f822d10c-9a88-463d-9a95-d5856eb9db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"sql_tool\",\n",
    "    description=(\n",
    "        \"Useful for answering questions about sql data\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d3907-69e2-4a30-b7a7-11128a8066aa",
   "metadata": {},
   "source": [
    "## Programs\n",
    "Depending the LLM, you will have to test with either OpenAIPydanticProgram or LLMTextCompletionProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10fe822a-44aa-4414-b83f-57fe27287586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from llama_index.program import OpenAIPydanticProgram, LLMTextCompletionProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecf708ff-fc74-4fd5-ab71-314a49010385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Song(BaseModel):\n",
    "    \"\"\"Data model for a song.\"\"\"\n",
    "\n",
    "    title: str\n",
    "    length_seconds: int\n",
    "\n",
    "\n",
    "class Album(BaseModel):\n",
    "    \"\"\"Data model for an album.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    artist: str\n",
    "    songs: List[Song]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8908ca7-1c61-43ec-9005-4528f7f0ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64dcf258-17c5-4f07-9571-9a36c264ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_str = \"\"\"\\\n",
    "Generate an example album, with an artist and a list of songs. \\\n",
    "Using the movie {movie_name} as inspiration.\\\n",
    "\"\"\"\n",
    "program = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(Album),\n",
    "    prompt_template_str=prompt_template_str,\n",
    "    llm=llm,\n",
    "    service_context = service_context,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e58bb3d-5667-4611-abb9-9c4a709fca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = program(movie_name=\"The Shining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b96dfe7e-4552-4a84-96ae-5818731ea5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Overlook Hotel Sessions' artist='The Shining Boys' songs=[Song(title='Rock & Roll Nightmare', length_seconds=3), Song(title='The Shine is Gone', length_seconds=4), Song(title='Redrum Riffs', length_seconds=2)]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85697b-0298-4c9a-bb96-3a6492084971",
   "metadata": {},
   "source": [
    "## Data Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878a963-3d80-4dfc-89dc-1407ff4ad335",
   "metadata": {},
   "source": [
    "Similar to programs, OpenAI LLMs will use OpenAIAgent, while other LLMs will use ReActAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f9d8741-967d-49dd-a42c-2b482f8044cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent, ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32d8b388-e8ca-4f7a-b142-2bde6619c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9bb26418-d5e3-4d92-aaae-a875ee5fb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    [vector_tool, summary_tool, sql_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    streaming = True,\n",
    "    #memory=ConversationBufferMemory( input_key=\"text\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e93a172-e871-4d88-b1a8-851a8fcc9c44",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index==0.9\n",
      "  Downloading llama_index-0.9.0-py3-none-any.whl (869 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.4/869.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tiktoken>=0.3.3 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (0.4.0)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (0.5.9)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (4.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (0.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (2023.6.0)\n",
      "Requirement already satisfied: httpx in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (0.23.3)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (2.0.18)\n",
      "Requirement already satisfied: urllib3<2 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (1.26.18)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (8.2.2)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (1.2.13)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8\n",
      "  Using cached nest_asyncio-1.5.8-py3-none-any.whl (5.3 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting openai>=1.1.0\n",
      "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beautifulsoup4<5.0.0,>=4.12.2\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Requirement already satisfied: numpy in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (1.24.4)\n",
      "Collecting aiostream<0.6.0,>=0.5.2\n",
      "  Downloading aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: pandas in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from llama_index==0.9) (1.4.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama_index==0.9) (2.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama_index==0.9) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama_index==0.9) (1.5.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from deprecated>=1.2.9.3->llama_index==0.9) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama_index==0.9) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama_index==0.9) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama_index==0.9) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama_index==0.9) (8.1.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from openai>=1.1.0->llama_index==0.9) (1.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from openai>=1.1.0->llama_index==0.9) (3.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from openai>=1.1.0->llama_index==0.9) (1.2.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from openai>=1.1.0->llama_index==0.9) (1.10.8)\n",
      "Requirement already satisfied: certifi in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from httpx->llama_index==0.9) (2022.9.24)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from httpx->llama_index==0.9) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from httpx->llama_index==0.9) (1.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index==0.9) (1.1.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from tiktoken>=0.3.3->llama_index==0.9) (2.31.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama_index==0.9) (0.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama_index==0.9) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama_index==0.9) (2022.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama_index==0.9) (3.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx->llama_index==0.9) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->llama_index==0.9) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->llama_index==0.9) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tubakaraca/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken>=0.3.3->llama_index==0.9) (2.0.4)\n",
      "Installing collected packages: nltk, nest-asyncio, beautifulsoup4, aiostream, openai, llama_index\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Uninstalling nest-asyncio-1.5.6:\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.1\n",
      "    Uninstalling beautifulsoup4-4.11.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "  Attempting uninstall: llama_index\n",
      "    Found existing installation: llama-index 0.8.3\n",
      "    Uninstalling llama-index-0.8.3:\n",
      "      Successfully uninstalled llama-index-0.8.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.4.1 which is incompatible.\n",
      "flax 0.7.4 requires jax>=0.4.2, but you have jax 0.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiostream-0.5.2 beautifulsoup4-4.12.2 llama_index-0.9.0 nest-asyncio-1.5.8 nltk-3.8.1 openai-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cca1ca6d-a8c5-4704-9ba6-529d5e626638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: Using the `vector_search` tool to search for specific facts.\n",
      "Action Input: {'title': 'DefaultToolFnSchema', 'description': 'Default tool function Schema.', 'type': 'object', 'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input']}\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Using the `vector_search` tool to search for specific facts.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_96426/1230412909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the Vector tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/base_query_engine.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mstr_or_query_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryBundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQueryType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRESPONSE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/callbacks/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcallback_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masync_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/types.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtrace_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_bundle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQueryBundle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRESPONSE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         agent_response = self.chat(\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mquery_bundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mchat_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/callbacks/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcallback_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masync_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, message, chat_history)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_chat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# given react prompt outputs, call tools or return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             reasoning_steps, is_done = self._process_actions(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36m_process_actions\u001b[0;34m(self, tools, output, is_streaming)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# call tool with input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mreasoning_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActionReasoningStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_reasoning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreasoning_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         with self.callback_manager.event(\n\u001b[1;32m    191\u001b[0m             \u001b[0mCBEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUNCTION_CALL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Using the `vector_search` tool to search for specific facts.'"
     ]
    }
   ],
   "source": [
    "# Test the Vector tool \n",
    "response = agent.query(\"Hello!\")\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e2804a3-d44d-4c19-ae04-b37e8f49132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of vector_search, summary, sql_tool) if using a tool.\n",
      "Action Input: {'text': 'hello world', 'num_beams': 5}\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tool name (one of vector_search, summary, sql_tool) if using a tool.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_96426/1591177659.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/callbacks/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcallback_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masync_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, message, chat_history)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_chat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# given react prompt outputs, call tools or return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             reasoning_steps, is_done = self._process_actions(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36m_process_actions\u001b[0;34m(self, tools, output, is_streaming)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# call tool with input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mreasoning_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActionReasoningStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_reasoning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreasoning_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         with self.callback_manager.event(\n\u001b[1;32m    191\u001b[0m             \u001b[0mCBEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUNCTION_CALL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tool name (one of vector_search, summary, sql_tool) if using a tool.'"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hello!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c6e21cf-d945-4646-9a5e-84d27ded56fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I can use the `vector_search` tool to help me answer the question about AC/DC tracks.\n",
      "Action: tool name (`vector_search`) if using a tool.\n",
      "Action Input: {'text': 'AC/DC', 'num_beams': 5}\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tool name (`vector_search`) if using a tool.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_96426/3902625558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What was mentioned about Meta? How Does it differ from how OpenAI is talked about?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/callbacks/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcallback_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masync_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, message, chat_history)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_chat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# given react prompt outputs, call tools or return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             reasoning_steps, is_done = self._process_actions(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36m_process_actions\u001b[0;34m(self, tools, output, is_streaming)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# call tool with input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mreasoning_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActionReasoningStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_reasoning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreasoning_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         with self.callback_manager.event(\n\u001b[1;32m    191\u001b[0m             \u001b[0mCBEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUNCTION_CALL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tool name (`vector_search`) if using a tool.'"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What was mentioned about Meta? How Does it differ from how OpenAI is talked about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "792fac31-4320-472f-ac3f-ea26c3207f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: Using the `vector_search` tool to search for specific facts about AC/DC tracks.\n",
      "Action Input: {'text': 'AC/DC', 'num_beams': 5}\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Using the `vector_search` tool to search for specific facts about AC/DC tracks.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_96426/2551319672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What are some tracks from the artist AC/DC? Limit it to 3?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/callbacks/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcallback_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masync_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, message, chat_history)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_chat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# given react prompt outputs, call tools or return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             reasoning_steps, is_done = self._process_actions(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/agent/react/base.py\u001b[0m in \u001b[0;36m_process_actions\u001b[0;34m(self, tools, output, is_streaming)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# call tool with input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mreasoning_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActionReasoningStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_reasoning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreasoning_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         with self.callback_manager.event(\n\u001b[1;32m    191\u001b[0m             \u001b[0mCBEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUNCTION_CALL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Using the `vector_search` tool to search for specific facts about AC/DC tracks.'"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What are some tracks from the artist AC/DC? Limit it to 3?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b500d89-18d1-4411-ab22-d601ad5a05ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
